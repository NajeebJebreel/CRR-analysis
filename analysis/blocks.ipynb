{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63258948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85867e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data2string(df):\n",
    "    vals = df.values.astype(str)\n",
    "    vals = np.array([' '.join(x) for x in vals])\n",
    "\n",
    "    # should be fine now, but this checks that nothing is getting truncated due to type casting\n",
    "    test = np.array([[y.isdigit() for y in x.split(' ')] for x in vals])\n",
    "    assert (test.sum(axis=-1) == df.shape[-1]).all()\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3450cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 299\n"
     ]
    }
   ],
   "source": [
    "# Blocks random\n",
    "files_orig_rand = glob.glob('../results/init_random/blocks/*original*.t7')\n",
    "files_rec_rand = glob.glob('../results/init_random/blocks/*reconstructed*.t7')\n",
    "files_orig_rand = sorted(files_orig_rand)\n",
    "files_rec_rand = sorted(files_rec_rand)\n",
    "print(len(files_orig_rand), len(files_rec_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of records, and the total number of record prototypes in the dataset\n",
    "records_in_orig = 0\n",
    "prototypes_in_orig = 0\n",
    "for i in range(len(files_orig_rand)):\n",
    "    orig_data = torch.load(files_orig_rand[i])\n",
    "    uniq_orig_data = orig_data.drop_duplicates().reset_index(drop=True)\n",
    "    records_in_orig+= len(orig_data)\n",
    "    prototypes_in_orig += len(uniq_orig_data)\n",
    "print('Blocks')\n",
    "print('Records in D:', records_in_orig)\n",
    "print('Prototypes in D:', prototypes_in_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907027fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of records, and the total number of record prototypes in the reconstructions (random)\n",
    "records_in_rec = 0\n",
    "prototypes_in_rec = 0\n",
    "for i in range(len(files_rec_rand)):\n",
    "    rec_data = torch.load(files_rec_rand[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "    \n",
    "    uniq_rec_data = all_rec_data.drop_duplicates().reset_index(drop=True)\n",
    "    records_in_rec+= len(all_rec_data)\n",
    "    prototypes_in_rec+= len(uniq_rec_data)\n",
    "\n",
    "print('Blocks (random)')\n",
    "print('Records in D\\':', records_in_rec)\n",
    "print('Prototypes in D\\':', prototypes_in_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765c24b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block (random):\n",
      "Records in D': 3696675\n",
      "Prototypes in D': 161346\n"
     ]
    }
   ],
   "source": [
    "# The total number of records, and the total number of record prototypes in the reconstructions that are not in the dataset (random)\n",
    "in_orig_rand = []\n",
    "in_rec_rand = []\n",
    "\n",
    "for i in range(len(files_orig_rand)):\n",
    "    orig_data = torch.load(files_orig_rand[i])\n",
    "    rec_data = torch.load(files_rec_rand[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "\n",
    "    orig_data_str = convert_data2string(orig_data)\n",
    "    all_rec_data_str = convert_data2string(all_rec_data)\n",
    "    uniq_rec_data = all_rec_data.drop_duplicates().reset_index(drop=True)\n",
    "    uniq_rec_data_str = convert_data2string(uniq_rec_data)\n",
    "    \n",
    "    \n",
    "    for prototype in uniq_rec_data_str:\n",
    "        n_in_orig = len(np.where(orig_data_str == prototype)[0])\n",
    "        n_in_rec = len(np.where(all_rec_data_str == prototype)[0])\n",
    "        in_orig_rand.append(n_in_orig)\n",
    "        in_rec_rand.append(n_in_rec)\n",
    "            \n",
    "in_orig_rand = np.array(in_orig_rand)\n",
    "in_rec_rand = np.array(in_rec_rand)\n",
    "idxs = (in_orig_rand == 0)\n",
    "print('Block (random):')\n",
    "print('Records in D\\':', in_rec_rand[idxs].sum()) \n",
    "print('Prototypes in D\\':', len(in_rec_rand[idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c595aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block (random) 1 in D:0.20%\n",
      "Block (random) 2 in D:0.15%\n",
      "Block (random) 3 in D:0.12%\n"
     ]
    }
   ],
   "source": [
    "# Percentage of appearances in reconstructions of rare record prototypes that occur once, twice, or three times in D\n",
    "idxs1 = (in_orig_rand == 1) * (in_rec_rand == 1)\n",
    "idxs2 = (in_rec_rand == 1)\n",
    "r1 = in_rec_rand[idxs1].sum()/in_rec_rand[idxs2].sum()\n",
    "\n",
    "print('Block (random) 1 in D:{:0.2f}%'.format(r1*100))\n",
    "\n",
    "idxs1 = (in_orig_rand == 2) * (in_rec_rand <= 2)\n",
    "idxs2 = (in_rec_rand <= 2)\n",
    "r2 = in_rec_rand[idxs1].sum()/in_rec_rand[idxs2].sum()\n",
    "\n",
    "print('Block (random) 2 in D:{:0.2f}%'.format(r2*100))\n",
    "\n",
    "\n",
    "idxs1 = (in_orig_rand == 3) * (in_rec_rand <= 3)\n",
    "idxs2 = (in_rec_rand <= 3)\n",
    "r3 = in_rec_rand[idxs1].sum()/in_rec_rand[idxs2].sum()\n",
    "\n",
    "print('Block (random) 3 in D:{:0.2f}%'.format(r3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00925470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block (random):\n",
      "Records in D: 1142\n",
      "Prototypes in D: 651\n"
     ]
    }
   ],
   "source": [
    "# The total number of records, and the total number of record prototypes in the dataset that are not in the reconstructions(random)\n",
    "\n",
    "in_orig_rand = []\n",
    "in_rec_rand = []\n",
    "\n",
    "for i in range(len(files_orig_rand)):\n",
    "    orig_data = torch.load(files_orig_rand[i])\n",
    "    rec_data = torch.load(files_rec_rand[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "\n",
    "    orig_data_str = convert_data2string(orig_data)\n",
    "    all_rec_data_str = convert_data2string(all_rec_data)\n",
    "    uniq_orig_data_str = convert_data2string(orig_data.drop_duplicates().reset_index(drop=True))\n",
    "    \n",
    "    for prototype in uniq_orig_data_str:\n",
    "        n_in_orig = len(np.where(orig_data_str == prototype)[0])\n",
    "        n_in_rec = len(np.where(all_rec_data_str == prototype)[0])\n",
    "        in_orig_rand.append(n_in_orig)\n",
    "        in_rec_rand.append(n_in_rec)\n",
    "            \n",
    "in_orig_rand = np.array(in_orig_rand)\n",
    "in_rec_rand = np.array(in_rec_rand)\n",
    "idxs = (in_rec_rand == 0)\n",
    "print('Block (random):')\n",
    "print('Records in D:', in_orig_rand[idxs].sum()) \n",
    "print('Prototypes in D:', len(in_orig_rand[idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualizing correlation\n",
    "in_orig_rand = []\n",
    "in_rec_rand = []\n",
    "\n",
    "for i in range(len(files_orig_rand)):\n",
    "    orig_data = torch.load(files_orig_rand[i])\n",
    "    rec_data = torch.load(files_rec_rand[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "\n",
    "    orig_data_prototypes = orig_data.drop_duplicates().reset_index(drop=True)\n",
    "    orig_data_str = convert_data2string(orig_data)\n",
    "    all_rec_data_str = convert_data2string(all_rec_data)\n",
    "    orig_data_prototypes = convert_data2string(orig_data_prototypes)\n",
    "    \n",
    "    for prototype in orig_data_prototypes:\n",
    "        n_in_orig = len(np.where(orig_data_str == prototype)[0])\n",
    "        n_in_rec = len(np.where(all_rec_data_str == prototype)[0])\n",
    "        in_orig_rand.append(n_in_orig)\n",
    "        in_rec_rand.append(n_in_rec)\n",
    "            \n",
    "\n",
    "in_orig_rand = np.array(in_orig_rand)\n",
    "in_rec_rand = np.array(in_rec_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82210cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), dpi= 300, facecolor='w', edgecolor='k')\n",
    "\n",
    "ax = sns.scatterplot(x = in_orig_rand, y = in_rec_rand,\n",
    "                edgecolor = \"black\", hue = in_rec_rand)\n",
    "ax.set(xlabel='Occurences in D', ylabel='Frequency in reconstructions')\n",
    "pr = pearsonr(in_orig_rand, in_rec_rand)\n",
    "# legend.get_frame().set_edgecolor('1.0')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_linewidth(0.5)\n",
    "ax.spines['left'].set_linewidth(0.5)\n",
    "\n",
    "# # set the x-spine (see below for more info on `set_position`)\n",
    "ax.spines['left'].set_position('zero')\n",
    "# turn off the right spine/ticks\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.yaxis.tick_left()\n",
    "# set the y-spine\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "# turn off the top spine/ticks\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.tick_bottom()\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.xlabel('Occurences in D')\n",
    "plt.ylabel('Frequency in reconstructions')\n",
    "plt.figtext(0.2, 0.65, f'Pearson\\'s r  = {pr.statistic:0.4f}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/corr_block_random.png', dpi = 300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21a00e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 299\n"
     ]
    }
   ],
   "source": [
    "# Blocks baseline\n",
    "files_orig_base = glob.glob('../results/init_baseline/blocks/*original*.t7')\n",
    "files_rec_base = glob.glob('../results/init_baseline/blocks/*reconstructed*.t7')\n",
    "files_orig_base = sorted(files_orig_base)\n",
    "files_rec_base = sorted(files_rec_base)\n",
    "print(len(files_orig_base), len(files_rec_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of records, and the total number of record prototypes in the reconstructions (baseline)\n",
    "records_in_rec = 0\n",
    "prototypes_in_rec = 0\n",
    "for i in range(len(files_rec_base)):\n",
    "    rec_data = torch.load(files_rec_base[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "    \n",
    "    uniq_rec_data = all_rec_data.drop_duplicates().reset_index(drop=True)\n",
    "    records_in_rec+= len(all_rec_data)\n",
    "    prototypes_in_rec+= len(uniq_rec_data)\n",
    "\n",
    "print('Block (baseline)')\n",
    "print('Records in D\\':', records_in_rec)\n",
    "print('Prototypes in D\\':', prototypes_in_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb88f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block (baseline):\n",
      "Records in D': 980412\n",
      "Prototypes in D': 88507\n"
     ]
    }
   ],
   "source": [
    "# The total number of records, and the total number of record prototypes in the reconstructions \n",
    "#that are not in the dataset (baseline)\n",
    "in_orig_base = []\n",
    "in_rec_base = []\n",
    "\n",
    "for i in range(len(files_orig_base)):\n",
    "    orig_data = torch.load(files_orig_base[i])\n",
    "    rec_data = torch.load(files_rec_base[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "\n",
    "    orig_data_str = convert_data2string(orig_data)\n",
    "    all_rec_data_str = convert_data2string(all_rec_data)\n",
    "    uniq_rec_data = all_rec_data.drop_duplicates().reset_index(drop=True)\n",
    "    uniq_rec_data_str = convert_data2string(uniq_rec_data)\n",
    "    \n",
    "    \n",
    "    for prototype in uniq_rec_data_str:\n",
    "        n_in_orig = len(np.where(orig_data_str == prototype)[0])\n",
    "        n_in_rec = len(np.where(all_rec_data_str == prototype)[0])\n",
    "        in_orig_base.append(n_in_orig)\n",
    "        in_rec_base.append(n_in_rec)\n",
    "            \n",
    "in_orig_base = np.array(in_orig_base)\n",
    "in_rec_base = np.array(in_rec_base)\n",
    "idxs = (in_orig_base == 0)\n",
    "print('Block (baseline):')\n",
    "print('Records in D\\':', in_rec_base[idxs].sum()) \n",
    "print('Prototypes in D\\':', len(in_rec_base[idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e76e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block (baseline) 1 in D:0.15%\n",
      "Block (baseline) 2 in D:0.06%\n",
      "Block (baseline) 3 in D:0.03%\n"
     ]
    }
   ],
   "source": [
    "# Percentage of appearances in reconstructions of rare record prototypes that occur once, twice, or three times in D\n",
    "idxs1 = (in_orig_base == 1) * (in_rec_base == 1)\n",
    "idxs2 = (in_rec_base == 1)\n",
    "r1 = in_rec_base[idxs1].sum()/in_rec_base[idxs2].sum()\n",
    "\n",
    "print('Block (baseline) 1 in D:{:0.2f}%'.format(r1*100))\n",
    "\n",
    "idxs1 = (in_orig_base == 2) * (in_rec_base <= 2)\n",
    "idxs2 = (in_rec_base <= 2)\n",
    "r2 = in_rec_base[idxs1].sum()/in_rec_base[idxs2].sum()\n",
    "\n",
    "print('Block (baseline) 2 in D:{:0.2f}%'.format(r2*100))\n",
    "\n",
    "\n",
    "idxs1 = (in_orig_base == 3) * (in_rec_base <= 3)\n",
    "idxs2 = (in_rec_base <= 3)\n",
    "r3 = in_rec_base[idxs1].sum()/in_rec_base[idxs2].sum()\n",
    "\n",
    "print('Block (baseline) 3 in D:{:0.2f}%'.format(r3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9993059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tract (baseline):\n",
      "Records in D: 293\n",
      "Prototypes in D: 199\n"
     ]
    }
   ],
   "source": [
    "# The total number of records, and the total number of record prototypes in the dataset that are not in the reconstructions(baseline)\n",
    "\n",
    "in_orig_base = []\n",
    "in_rec_base = []\n",
    "\n",
    "for i in range(len(files_orig_base)):\n",
    "    orig_data = torch.load(files_orig_base[i])\n",
    "    rec_data = torch.load(files_rec_base[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "\n",
    "    orig_data_str = convert_data2string(orig_data)\n",
    "    all_rec_data_str = convert_data2string(all_rec_data)\n",
    "    uniq_orig_data_str = convert_data2string(orig_data.drop_duplicates().reset_index(drop=True))\n",
    "    \n",
    "    for prototype in uniq_orig_data_str:\n",
    "        n_in_orig = len(np.where(orig_data_str == prototype)[0])\n",
    "        n_in_rec = len(np.where(all_rec_data_str == prototype)[0])\n",
    "        in_orig_base.append(n_in_orig)\n",
    "        in_rec_base.append(n_in_rec)\n",
    "            \n",
    "in_orig_base = np.array(in_orig_base)\n",
    "in_rec_base = np.array(in_rec_base)\n",
    "idxs = (in_rec_base == 0)\n",
    "print('Block (baseline):')\n",
    "print('Records in D:', in_orig_base[idxs].sum()) \n",
    "print('Prototypes in D:', len(in_orig_base[idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefda1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualizing correlation\n",
    "\n",
    "in_orig_base = []\n",
    "in_rec_base = []\n",
    "\n",
    "for i in range(len(files_orig_base)):\n",
    "    orig_data = torch.load(files_orig_base[i])\n",
    "    rec_data = torch.load(files_rec_base[i])\n",
    "    all_rec_data = None\n",
    "    for d in rec_data:\n",
    "        if all_rec_data is None:\n",
    "            all_rec_data = d\n",
    "        else:\n",
    "            all_rec_data = pd.concat([all_rec_data, d])\n",
    "\n",
    "    orig_data_prototypes = orig_data.drop_duplicates().reset_index(drop=True)\n",
    "    orig_data_str = convert_data2string(orig_data)\n",
    "    all_rec_data_str = convert_data2string(all_rec_data)\n",
    "    orig_data_prototypes = convert_data2string(orig_data_prototypes)\n",
    "    \n",
    "    for prototype in orig_data_prototypes:\n",
    "        n_in_orig = len(np.where(orig_data_str == prototype)[0])\n",
    "        n_in_rec = len(np.where(all_rec_data_str == prototype)[0])\n",
    "        in_orig_base.append(n_in_orig)\n",
    "        in_rec_base.append(n_in_rec)\n",
    "            \n",
    "\n",
    "in_orig_base = np.array(in_orig_base)\n",
    "in_rec_base = np.array(in_rec_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), dpi= 300, facecolor='w', edgecolor='k')\n",
    "\n",
    "ax = sns.scatterplot(x = in_orig_base, y = in_rec_base,\n",
    "                edgecolor = \"black\", hue = in_rec_base)\n",
    "ax.set(xlabel='Occurences in D', ylabel='Frequency in reconstructions')\n",
    "pr = pearsonr(in_orig_base, in_rec_base)\n",
    "# legend.get_frame().set_edgecolor('1.0')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_linewidth(0.5)\n",
    "ax.spines['left'].set_linewidth(0.5)\n",
    "\n",
    "# # set the x-spine (see below for more info on `set_position`)\n",
    "ax.spines['left'].set_position('zero')\n",
    "# turn off the right spine/ticks\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.yaxis.tick_left()\n",
    "# set the y-spine\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "# turn off the top spine/ticks\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.tick_bottom()\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.xlabel('Occurences in D')\n",
    "plt.ylabel('Frequency in reconstructions')\n",
    "plt.figtext(0.2, 0.65, f'Pearson\\'s r  = {pr.statistic:0.4f}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/corr_block_baseline.png', dpi = 300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
